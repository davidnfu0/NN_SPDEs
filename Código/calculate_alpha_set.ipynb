{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e7b94d",
   "metadata": {},
   "source": [
    "# En este notebook se calculara y guardará un AlphaSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6a52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import scipy.special as scsp\n",
    "\n",
    "sys.path.append(\"src\")\n",
    "from src.AlphaSet import AlphaSet\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74626206",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6987c2",
   "metadata": {},
   "source": [
    "## Parámetros para el AlphaSet\n",
    "- I: Dimensión del Movimiento Browniano\n",
    "- J: Largo de los alphas que generan los Polinomios de Wick\n",
    "- K: Grado máximo de los Polinomios de Wick\n",
    "- n: Cantidad de divisiones de tiempo para el Movimiento Browniano\n",
    "- T: Tiempo total del Movimiento Browniano\n",
    "- NNormals: Cantidad de Normales (Omegas) que se van a generar para entrenar / evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0955daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "I, J, K, n, T, NNormals = 1, 50, 2, 100, 0.25, 20\n",
    "batch_size = 2 # Para calcular en tandas\n",
    "SEED = 69\n",
    "pkl_file = f\"files/alpha_set_I{I}_J{J}_K{K}_n{n}_T{T}.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70af857",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5650bc96",
   "metadata": {},
   "source": [
    "## Generar el AlphaSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "638cea89",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m np.random.seed(SEED)\n\u001b[32m      4\u001b[39m alpha_set = AlphaSet(I, J, K, n, T)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43malpha_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalculate_alphas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m start_time = time.time()\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NNormals):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\urbin\\OneDrive\\Escritorio\\UChile\\DIM\\5to Semestre\\EDPN\\NN_SPDEs\\Código\\src\\AlphaSet.py:114\u001b[39m, in \u001b[36mAlphaSet.calculate_alphas\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    111\u001b[39m i, j, k = \u001b[38;5;28mself\u001b[39m.I, \u001b[38;5;28mself\u001b[39m.J, \u001b[38;5;28mself\u001b[39m.K\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m alpha_matrix \u001b[38;5;129;01min\u001b[39;00m itt.product(\u001b[38;5;28mrange\u001b[39m(k + \u001b[32m1\u001b[39m), repeat = i * j):\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     total = \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43malpha_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m total <= k:\n\u001b[32m    116\u001b[39m         alpha = Alpha(i, j, np.reshape(alpha_matrix, (i, j)))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Método lento\n",
    "\n",
    "np.random.seed(SEED)\n",
    "alpha_set = AlphaSet(I, J, K, n, T)\n",
    "alpha_set.calculate_alphas()\n",
    "start_time = time.time()\n",
    "for _ in range(NNormals):\n",
    "    normal = np.random.normal(size=(I, J))\n",
    "    alpha_set.normals.append(normal)\n",
    "alpha_set.calculate_wick_values()\n",
    "alpha_set.calculate_increments()\n",
    "alpha_set.evaluate_paths()\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Time taken for slow method: {elapsed_time:.2f} seconds\")\n",
    "alpha_set.save_alpha_set(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bbd7c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardadas 7/20\n",
      "Guardadas 9/20\n",
      "Guardadas 11/20\n",
      "Guardadas 13/20\n",
      "Guardadas 15/20\n",
      "Guardadas 17/20\n",
      "Guardadas 19/20\n",
      "Guardadas 20/20\n",
      "Tiempo total: 0.22 segundos\n",
      "AlphaSet completo ✔\n"
     ]
    }
   ],
   "source": [
    "# Cargar o crear\n",
    "np.random.seed(SEED)\n",
    "if os.path.exists(pkl_file):\n",
    "    with open(pkl_file, \"rb\") as f:\n",
    "        aset = pickle.load(f)\n",
    "else:\n",
    "    aset = AlphaSet(I, J, K, n, T)\n",
    "    aset.calculate_alphas_fast()\n",
    "\n",
    "# Bucle incremental\n",
    "start = time.time()\n",
    "while len(aset.normals) < NNormals:\n",
    "    remaining = NNormals - len(aset.normals)\n",
    "    b = min(batch_size, remaining)\n",
    "    normals = np.random.normal(size=(b, I, J))\n",
    "    aset.add_normals(normals)\n",
    "\n",
    "    # checkpoint\n",
    "    with open(pkl_file, \"wb\") as f:\n",
    "        pickle.dump(aset, f)\n",
    "    print(f\"Guardadas {len(aset.normals)}/{NNormals}\")\n",
    "end = time.time() - start\n",
    "print(f\"Tiempo total: {end:.2f} segundos\")\n",
    "print(\"AlphaSet completo ✔\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bd675a",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60779abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo slow  : 1.041 s\n",
      "Tiempo fast  : 0.003 s\n",
      "Índices α idénticos: True\n",
      "\n",
      "================ RESULTADO ================\n",
      "¡Métodos equivalentes! ✅\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "I, J, K, n, T = 1, 15, 2, 50, 0.25\n",
    "N_NORMALS     = 3\n",
    "SEED          = 123\n",
    "atol          = 1e-12\n",
    "\n",
    "# ---------- 1. AlphaSet (lento: calculate_alphas original) -------\n",
    "np.random.seed(SEED)\n",
    "slow = AlphaSet(I, J, K, n, T)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "slow.calculate_alphas()          #  ← versión exhaustiva original\n",
    "print(f\"Tiempo slow  : {time.perf_counter()-t0:.3f} s\")\n",
    "\n",
    "# ---------- 2. AlphaSet (rápido: nueva función) ------------------\n",
    "np.random.seed(SEED)\n",
    "fast = AlphaSet(I, J, K, n, T)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "fast.calculate_alphas_fast()     #  ← tu función optimizada\n",
    "print(f\"Tiempo fast  : {time.perf_counter()-t0:.3f} s\")\n",
    "\n",
    "# ---------- 3. Comprobar que los α son los mismos ---------------\n",
    "def alphas_to_set(alpha_dict):\n",
    "    return {\n",
    "        k: {tuple(a.values.flatten()) for a in lst}\n",
    "        for k, lst in alpha_dict.items()\n",
    "    }\n",
    "\n",
    "same_alphas = alphas_to_set(slow.alphas) == alphas_to_set(fast.alphas)\n",
    "print(\"Índices α idénticos:\", same_alphas)\n",
    "\n",
    "# ---------- 4. Continuamos pipeline para corroborar todo ---------\n",
    "normals = np.random.normal(size=(N_NORMALS, I, J))\n",
    "slow.add_normals(copy.deepcopy(normals))\n",
    "fast.add_normals(copy.deepcopy(normals))\n",
    "\n",
    "def deep_equal(a, b):\n",
    "    if isinstance(a, list):\n",
    "        return len(a) == len(b) and all(deep_equal(x, y) for x, y in zip(a, b))\n",
    "    if isinstance(a, dict):\n",
    "        return a.keys() == b.keys() and all(deep_equal(a[k], b[k]) for k in a)\n",
    "    return np.allclose(np.asarray(a), np.asarray(b), atol=atol, rtol=0)\n",
    "\n",
    "ok = (\n",
    "    deep_equal(slow.wick_values,         fast.wick_values)         and\n",
    "    deep_equal(slow.brownian_increments, fast.brownian_increments) and\n",
    "    deep_equal(slow.brownian_paths,      fast.brownian_paths)\n",
    ")\n",
    "\n",
    "print(\"\\n================ RESULTADO ================\")\n",
    "print(\"¡Métodos equivalentes! ✅\" if (same_alphas and ok) else \"❌  Hay diferencias\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c8980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaSet clásico listo\n",
      "AlphaSet rápido creado de cero\n",
      "Guardadas 2/5\n",
      "Guardadas 4/5\n",
      "Guardadas 5/5\n",
      "AlphaSet rápido completo ✔\n",
      "\n",
      "==================== RESULTADO ====================\n",
      "AlphaSets equivalentes ✔✔\n"
     ]
    }
   ],
   "source": [
    "# ---------------- PARÁMETROS ----------------\n",
    "I, J, K, n, T    = 1, 16, 2, 100, 0.25\n",
    "NNormals         = 5          # número total de normales a precalcular\n",
    "batch_size       = 2          # tamaño de lote para el método rápido\n",
    "SEED             = 69         # semilla para reproducibilidad\n",
    "pkl_file = f\"files/alpha_set_I{I}_J{J}_K{K}_n{n}_T{T}.pkl\"\n",
    "atol_compare     = 1e-12      # tolerancia de np.allclose\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "# ---------- 1. AlphaSet \"clásico\" --------------------------\n",
    "np.random.seed(SEED)\n",
    "classic = AlphaSet(I, J, K, n, T)\n",
    "classic.calculate_alphas()\n",
    "\n",
    "for _ in range(NNormals):\n",
    "    classic.normals.append(np.random.normal(size=(I, J)))\n",
    "classic.calculate_wick_values()\n",
    "classic.calculate_increments()\n",
    "classic.evaluate_paths()\n",
    "print(\"AlphaSet clásico listo\")\n",
    "\n",
    "\n",
    "# ---------- 2. AlphaSet \"rápido / incremental\" ------------\n",
    "np.random.seed(SEED)                       # MISMA semilla\n",
    "if os.path.exists(pkl_file):\n",
    "    with open(pkl_file, \"rb\") as f:\n",
    "        fast = pickle.load(f)\n",
    "    print(\"Checkpoint encontrado.  Normales actuales:\", len(fast.normals))\n",
    "else:\n",
    "    fast = AlphaSet(I, J, K, n, T)\n",
    "    fast.calculate_alphas()\n",
    "    print(\"AlphaSet rápido creado de cero\")\n",
    "\n",
    "while len(fast.normals) < NNormals:\n",
    "    remaining = NNormals - len(fast.normals)\n",
    "    b = min(batch_size, remaining)\n",
    "    normals = np.random.normal(size=(b, I, J))\n",
    "    fast.add_normals(normals)\n",
    "\n",
    "    with open(pkl_file, \"wb\") as f:\n",
    "        pickle.dump(fast, f)\n",
    "    print(f\"Guardadas {len(fast.normals)}/{NNormals}\")\n",
    "\n",
    "print(\"AlphaSet rápido completo ✔\")\n",
    "\n",
    "\n",
    "# ---------- 3. Función de comparación ----------------------\n",
    "def compare(a, b, name, atol=atol_compare):\n",
    "    \"\"\"\n",
    "    Compara recursivamente listas, diccionarios y arrays.\n",
    "    Devuelve True si son iguales (hasta atol) y False en caso contrario.\n",
    "    \"\"\"\n",
    "    if isinstance(a, list):\n",
    "        if len(a) != len(b):\n",
    "            print(f\"{name}: len diferente ({len(a)} vs {len(b)})\")\n",
    "            return False\n",
    "        return all(compare(x, y, f\"{name}[{i}]\", atol) for i, (x, y) in enumerate(zip(a, b)))\n",
    "\n",
    "    if isinstance(a, dict):\n",
    "        if a.keys() != b.keys():\n",
    "            print(f\"{name}: claves distintas\")\n",
    "            return False\n",
    "        return all(compare(a[k], b[k], f\"{name}['{k}']\", atol) for k in a)\n",
    "\n",
    "    # caso base: array / escalar\n",
    "    eq = np.allclose(np.asarray(a), np.asarray(b), rtol=0, atol=atol)\n",
    "    if not eq:\n",
    "        diff = np.max(np.abs(np.asarray(a) - np.asarray(b)))\n",
    "        print(f\"{name}: no coincide (max |Δ| = {diff})\")\n",
    "    return eq\n",
    "\n",
    "\n",
    "# ---------- 4. LLAMAR A LA COMPARACIÓN ---------------------\n",
    "ok = (\n",
    "    compare(classic.normals,             fast.normals,             \"normals\") and\n",
    "    compare(classic.wick_values,         fast.wick_values,         \"wick_values\") and\n",
    "    compare(classic.brownian_increments, fast.brownian_increments, \"increments\") and\n",
    "    compare(classic.brownian_paths,      fast.brownian_paths,      \"paths\")\n",
    ")\n",
    "\n",
    "print(\"\\n==================== RESULTADO ====================\")\n",
    "print(\"AlphaSets equivalentes ✔✔\" if ok else \"¡Los AlphaSets difieren!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
